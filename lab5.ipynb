{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iLp7lFyxZ0PZ1-NyGKGVO18_saZn_FRo",
      "authorship_tag": "ABX9TyPmxPrlxTGQv6JU6ubdAoE6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moter1026/review_Kinopoisk_lab5/blob/main/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voNVDROxhYSt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import math\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import PorterStemmer\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import copy_dataset_random\n",
        "from lab4 import make_dataFrame\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "sys.path.insert(0, \"/content/drive/MyDrive/lab5_drive\")\n",
        "%cd /content/drive/MyDrive/lab5_drive/\n",
        "\n",
        "allBadComments = os.listdir(\"/content/drive/MyDrive/lab5_drive/dataset/bad\")\n",
        "allGoodComments = os.listdir(\"/content/drive/MyDrive/lab5_drive/dataset/good\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "разделяю списки со всеми хорошими и плохими элементами в пропорциях 80:10:10,\n",
        "где 80% - это для обучения, 10% - для тестов, 10% - для валинации"
      ],
      "metadata": {
        "id": "XwstTem0cwWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countForBadLearn = math.floor(len(allBadComments)*0.8)\n",
        "countForGoodLearn = math.floor(len(allGoodComments)*0.8)\n",
        "\n",
        "learnBadFiles = allBadComments[0:countForBadLearn]\n",
        "learnGoodFiles = allGoodComments[0:countForGoodLearn]\n",
        "\n",
        "learnBadDf = pd.DataFrame(learnBadFiles,columns=[\"Bad Names\"])\n",
        "learnGoodDf = pd.DataFrame(learnGoodFiles,columns=[\"Good Names\"])\n",
        "print(learnBadDf)\n",
        "print(learnGoodDf)\n",
        "\n",
        "\n",
        "testBadFiles = allBadComments[countForBadLearn : countForBadLearn + math.floor(len(allBadComments) * 0.1)]\n",
        "testGoodFiles = allGoodComments[countForGoodLearn : countForGoodLearn + math.floor(len(allGoodComments) * 0.1)]\n",
        "\n",
        "testBadDf = pd.DataFrame(testBadFiles, columns=[\"bad files for test\"])\n",
        "testGoodDf = pd.DataFrame(testGoodFiles, columns=[\"good files for test\"])\n",
        "print(testBadDf)\n",
        "print(testGoodDf)\n",
        "\n",
        "\n",
        "validBadFiles = allBadComments[countForBadLearn + math.floor(len(allBadComments) * 0.1):]\n",
        "validGoodFiles = allGoodComments[countForGoodLearn + math.floor(len(allGoodComments) * 0.1):]\n",
        "\n",
        "validBadDf = pd.DataFrame(validBadFiles, columns=[\"bad files for valid\"])\n",
        "validGoodDf = pd.DataFrame(validGoodFiles, columns=[\"good files for valid\"])\n",
        "print(validBadDf)\n",
        "print(validGoodDf)"
      ],
      "metadata": {
        "id": "vHQkkz7pc5s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "объеденю dataFrames для обучения в один с рандомно расположенными файлами"
      ],
      "metadata": {
        "id": "2t9pef2Rk5d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learnAllFilesDf = pd.concat([learnBadFiles, learnGoodFiles], ignore_index=True).sample(frac=1, random_state=)"
      ],
      "metadata": {
        "id": "Q6-A1hdmm3yw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}